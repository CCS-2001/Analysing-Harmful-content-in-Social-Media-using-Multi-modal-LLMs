{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4b19a1-0b25-4133-9ec0-9104c4882c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torch, re\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "from utils import retrieve_dataset, display_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7add66-551b-494e-b270-2efb6d913362",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614704c0-3bf0-4a3a-b96c-7a89270d3c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load the model and processor\n",
    "model_path = 'microsoft/Phi-3-vision-128k-instruct'\n",
    "\n",
    "kwargs = {}\n",
    "kwargs['torch_dtype'] = torch.bfloat16\n",
    "processor = AutoProcessor.from_pretrained(model_path, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, \n",
    "                                             trust_remote_code=True, \n",
    "                                             torch_dtype=\"auto\").cuda()\n",
    "model_name = 'Phi 3 Vision'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe56988-8764-4935-acfa-68c4ed1608ef",
   "metadata": {},
   "source": [
    "# Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5817a2c0-737f-45a1-9b15-d3b5e5c094a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to format the prompt to be given to a LLM\n",
    "\n",
    "Inputs:\n",
    "    sample (dict): a dictionary containing a single sample from a dataset\n",
    "    category (str): the category of harmful content\n",
    "    fs_all (list): list of few shot prompts of the dataste\n",
    "    cot_prompt (str): the chain of thought prompt of the dataset\n",
    "    num_shot (int): number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "    multimodal (bool): whether the dataset is multimodal or not, default is False\n",
    "\n",
    "Returns:\n",
    "    prompt (str): the prompt to be given to a LLM\n",
    "    label (str): the label of the text\n",
    "\n",
    "'''\n",
    "def format_prompt(sample, category, fs_all, cot_prompt, num_shot=0, cot=False, multimodal=False):\n",
    "    if sample['text'] is not None:\n",
    "        text = '###TEXT: ' + sample['text']\n",
    "    label = sample['label']\n",
    "    label_dict = {0: 'NO',\n",
    "                 1: 'YES'}\n",
    "\n",
    "    user_prompt = '<|user|>\\n'\n",
    "    assistant_prompt = '<|assistant|>\\n'\n",
    "    prompt_suffix = \"<|end|>\\n\"\n",
    "\n",
    "    # define the instruction\n",
    "    if multimodal:\n",
    "        instruction = f'###INSTRUCTION: Given the following image, classify it as either {category} (YES) or not (NO). \\\n",
    "If it is {category}, answer YES. If it is not {category}, answer NO. You must answer with only YES or NO.'    \n",
    "        text = '<|image_1|>'\n",
    "        \n",
    "    elif cot:\n",
    "        instruction = f'###INSTRUCTION: Given the following text, classify it as either {category} (YES) or not (NO). \\\n",
    "Provide a rationale to your answer then give the answer as YES or NO.'\n",
    "        \n",
    "    else:\n",
    "        instruction = f'###INSTRUCTION: Given the following text, classify it as either {category} (YES) or not (NO). \\\n",
    "If it is {category}, answer YES. If it is not {category}, answer NO. You must answer with only YES or NO.'    \n",
    "\n",
    "    # define the prompt based on the prompting technique\n",
    "    if num_shot:\n",
    "        fs_prompt = 'Below are a set of instructions with a question, along with answers.\\n'\n",
    "        fs_prompt += '\\n\\n'.join(fs_all[0:num_shot])\n",
    "        ques = f'''{fs_prompt} \n",
    "        \n",
    "Now answer the following question.\n",
    "{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "    \n",
    "    elif cot:\n",
    "        ques = f'''Below is an instruction with a question, along with the answer to the question and the rationale.\n",
    "{instruction}\n",
    "{cot_prompt}\n",
    "\n",
    "Now answer the following question by giving a rationale and answer.\n",
    "{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "    \n",
    "    else:     \n",
    "        ques = f'''{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "\n",
    "    prompt = f\"{user_prompt}{ques}{prompt_suffix}{assistant_prompt}\"\n",
    "        \n",
    "    return prompt, label_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc7d9a9d-693f-4425-aa66-ba20ea3a4a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to inference and evaluate a LLM\n",
    "\n",
    "Inputs:\n",
    "    model_name (str): name of the language model\n",
    "    dataset_name (str): name of the dataset\n",
    "    category (str): the category of harmful content\n",
    "    num_shot (int): the number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "    num_examples (int): the number of examples to pass to the LLM, default is None\n",
    "    multimodal (bool): whether the dataset is multimodal, default is False\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "'''\n",
    "def llm_inf(model_name, dataset_name, category, num_shot=0, cot=False, num_examples=None, multimodal=False):\n",
    "    \n",
    "    # retrieve the dataset details\n",
    "    ds, fs_all, cot_prompt = retrieve_dataset(dataset_name, category, multimodal=multimodal)\n",
    "    print('Length of', dataset_name, 'test set:', len(ds))\n",
    "\n",
    "    # if no number of examples are provided, use the size of the test set\n",
    "    if num_examples is None:\n",
    "        num_examples = len(ds)\n",
    "        \n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # go through each example\n",
    "    for i in range(num_examples):\n",
    "        # format the prompt for the LLM\n",
    "        prompt, label = format_prompt(ds[i], category, fs_all, cot_prompt, num_shot, cot, multimodal)\n",
    "\n",
    "        # setting up the inputs and inference the model\n",
    "        if multimodal:\n",
    "            image = Image.open(f'Datasets/{dataset_name}/Images/' + ds['image_name'][i])\n",
    "            inputs = processor(prompt, image, return_tensors=\"pt\").to('cuda')\n",
    "        else:\n",
    "            inputs = processor(prompt, images=None, return_tensors=\"pt\").to('cuda')\n",
    "    \n",
    "        generate_ids = model.generate(**inputs, \n",
    "                                        max_new_tokens=256,\n",
    "                                        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "                                        do_sample=False,\n",
    "                                        temperature=None,\n",
    "                                        top_p=None,\n",
    "                                        top_k=None\n",
    "                                      )\n",
    "        generate_ids = generate_ids[:, inputs['input_ids'].shape[1]:]\n",
    "\n",
    "        # extract the response of the model\n",
    "        response = processor.batch_decode(generate_ids, \n",
    "                                          skip_special_tokens=True, \n",
    "                                          clean_up_tokenization_spaces=False)[0]\n",
    "        response = response.split('.')[0]\n",
    "        print('Q', i+1)\n",
    "        # print(prompt)\n",
    "        # print(\"model answer: \", response)\n",
    "\n",
    "        llm_answer = 'NO'\n",
    "\n",
    "        # use regular expression to extract exact answer from the model\n",
    "        match1 = re.findall(r'\\b(yes|no)\\b', response, re.IGNORECASE)\n",
    "        match2 = re.findall(r'cannot (moderate|classify)', response)\n",
    "\n",
    "        if match1:\n",
    "            llm_answer = match1[0].upper()\n",
    "        elif match2:\n",
    "            llm_answer = 'YES'\n",
    "\n",
    "        # print('llm answer:', llm_answer)\n",
    "            \n",
    "        # check if answer from model matches the actual answer\n",
    "        if llm_answer.upper().strip() == label:\n",
    "            correct += 1\n",
    "    \n",
    "        true_labels.append(label)\n",
    "        pred_labels.append(llm_answer)\n",
    "\n",
    "    # display the metric scores when all samples have been run\n",
    "    print()\n",
    "    display_results(true_labels, pred_labels, ['YES', 'NO'], model_name, dataset_name, num_shot, cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98c7b6-2a55-466d-9859-4e4fd61d19ec",
   "metadata": {},
   "source": [
    "# HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "527239d3-d6b2-4ffb-95fa-2b45fe8e331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'HateXplain'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f02aa-8132-4403-91e6-a582c9a93058",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81736d-1c63-4ee7-9463-d26d8ee31762",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e322e0d-95b5-439f-8743-930ce20c0158",
   "metadata": {},
   "source": [
    "# Toraman hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e68ff1ea-bea5-4e4d-b597-833af6c46809",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toraman hate speech'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c935a2b9-cdef-400b-9e90-1b02541f1ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23a4827-7c55-4a69-a60c-579ff2d70e51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a1249-0bb9-4d69-b445-25142f71143f",
   "metadata": {},
   "source": [
    "# OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57be9593-5039-41eb-8b90-ddfd3aa22b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OLID'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bc59a9-7898-493c-a1bf-1f56706748fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153340f9-2ba6-4b1a-9967-9cc9d3c17c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c9236-af9f-4bdd-911b-c40d2fecb228",
   "metadata": {},
   "source": [
    "# OffensEval-TR 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88108e21-45e8-4f40-ab23-b2abdab4de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OffensEval-TR 2020'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19fea0-8477-4c27-a8d7-952cdd2a2486",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3e6b38-aa94-435d-a7d4-2b41165a8350",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d04140a-6b40-4f3e-a521-f738073335c5",
   "metadata": {},
   "source": [
    "# Toxigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f4f01aa-dab4-4132-8449-b181225e1699",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toxigen'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9040f89e-4aa0-47f0-9777-14f6b78363ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175cd88-193d-4f06-a74c-e3477d9156ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885aaa0f-4fa8-49a6-831b-9a3ad4a81a21",
   "metadata": {},
   "source": [
    "# LLM-JP Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd7772e6-777a-4bbb-8aa6-0d4262b916e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LLM-JP Toxicity'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f500b-65db-4939-a5ac-d151d83f1839",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b620d-892d-46eb-a3ba-123eadd51ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff620e0-4c4b-4439-9823-b2d2bc0686c0",
   "metadata": {},
   "source": [
    "# Ejaz cyberbullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2b1c6ff-911d-4e9c-91f7-c3a174439d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Ejaz cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd52aab0-3ba6-4ae8-9bc8-63bbe5725205",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957058b-e732-43c3-97db-260cc0133f98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ce970f-58fe-44d7-9679-837a6a15d33b",
   "metadata": {},
   "source": [
    "# SOSNet cyberbullying\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f393fbb-b60f-4af2-a1e1-3c0376ef6c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SOSNet cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409fea38-7a04-4ec1-8e95-634fe423de6a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133a362-2932-4638-8f7f-e69b84782d3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed89bf5a-8dbb-4bfb-bd4c-51e9c5683c48",
   "metadata": {},
   "source": [
    "# MMHS150K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b04ff0-3baf-47ce-aad1-dc4f03a73fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MMHS150K'\n",
    "category = 'hate speech'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af4562e-ed36-4666-bff6-d511991cd162",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df9c3ab-4f9f-4f9b-ab9a-0c4a43774651",
   "metadata": {},
   "source": [
    "# MultiOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a5ca5c4-8c0f-4909-9a20-01be0d4bf712",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiOFF'\n",
    "category = 'offensive'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a615e-fb03-47f2-a4e9-0bdb72dcb09d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13a10c3-03f0-404d-92b8-baccf1b249be",
   "metadata": {},
   "source": [
    "# MultiToxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9c2446-60db-40ef-9f03-f407ed3a6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiToxic'\n",
    "category = 'toxic'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19350901-904f-4855-a63a-e2b62507ade5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849898c-d006-4aff-b76d-ab28a4e890f4",
   "metadata": {},
   "source": [
    "# MultiBully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf774d29-6597-46e9-9004-c8be34e83899",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiBully'\n",
    "category = 'cyberbullying'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcf49e-6106-4132-a9d8-c441ccf6ee57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
