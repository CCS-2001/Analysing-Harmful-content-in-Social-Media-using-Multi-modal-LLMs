{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396d223-910c-48b6-a0d0-14587cd321db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "import torch, re\n",
    "from PIL import Image\n",
    "from utils import retrieve_dataset, display_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a533a6e-1a43-4e3d-9382-87490ef43e63",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fd59a5-8b2b-4dae-8baf-e07d5a0c2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model and processor\n",
    "model_id = 'llava-hf/llava-v1.6-vicuna-7b-hf'\n",
    "processor = LlavaNextProcessor.from_pretrained(model_id)\n",
    "\n",
    "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    low_cpu_mem_usage=True,\n",
    "    device_map = 'auto'\n",
    ").cuda()\n",
    "model_name = 'LlaVa-Next Vicuna'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14ae97-b94a-4df7-9b0e-3fe660dec5a6",
   "metadata": {},
   "source": [
    "# Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "196fbb47-654d-4f72-9405-78e5d0d7eb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to format the prompt to be given to a LLM\n",
    "\n",
    "Inputs:\n",
    "    sample (dict): a dictionary containing a single sample from a dataset\n",
    "    category (str): the category of harmful content\n",
    "    fs_all (list): list of few shot prompts of the dataste\n",
    "    cot_prompt (str): the chain of thought prompt of the dataset\n",
    "    num_shot (int): number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "    multimodal (bool): whether the dataset is multimodal, default is False\n",
    "\n",
    "Returns:\n",
    "    prompt (str): the prompt to be given to a LLM\n",
    "    label (str): the label of the text\n",
    "\n",
    "'''\n",
    "def format_prompt(sample, category, fs_all, cot_prompt, num_shot=0, cot=False, multimodal=False):\n",
    "    if sample['text'] is not None:\n",
    "        text = '###TEXT: ' + sample['text']\n",
    "    label = sample['label']\n",
    "    label_dict = {0: 'NO',\n",
    "                 1: 'YES'}\n",
    "\n",
    "    # define the instruction\n",
    "    if multimodal:\n",
    "        instruction = f'Is the image considered {category}? Answer with either YES or NO.'\n",
    "        text = ''\n",
    "    elif cot:\n",
    "        instruction = f'###INSTRUCTION: Given the following text, classify it as either {category} (YES) or not (NO). \\\n",
    "Provide a rationale to your answer then give the answer as YES or NO.'\n",
    "    else:\n",
    "        instruction = f'###INSTRUCTION: Given the following text, classify it as either {category} (YES) or not (NO). \\\n",
    "If it is {category}, answer YES. If it is not {category}, answer NO. You must answer with only YES or NO.'    \n",
    "\n",
    "    # define the prompt based on the prompting technique\n",
    "    if num_shot:\n",
    "        fs_prompt = 'Below are a set of instructions with a question, along with answers.\\n'\n",
    "        fs_prompt += '\\n\\n'.join(fs_all[0:num_shot])\n",
    "        prompt = f'''{fs_prompt} \n",
    "        \n",
    "Now answer the following question.\n",
    "{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "\n",
    "    elif cot:\n",
    "        prompt = f'''Below is an instruction with a question, along with the answer to the question and the rationale.\n",
    "{instruction}\n",
    "{cot_prompt}\n",
    "\n",
    "Now answer the following question by giving a rationale and answer.\n",
    "{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "    else:     \n",
    "        prompt = f'''{instruction}\n",
    "{text}\n",
    "###ANSWER:'''\n",
    "\n",
    "\n",
    "    return prompt, label_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "493af593-3d72-44ad-b754-59a04614da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to inference and evaluate a LLM\n",
    "\n",
    "Inputs:\n",
    "    model_name (str): name of the language model\n",
    "    dataset_name (str): name of the dataset\n",
    "    category (str): the category of harmful content\n",
    "    num_shot (int): the number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "    num_examples (int): the number of examples to pass to the LLM, default is None\n",
    "    multimodal (bool): whether the dataset is multimodal, default is False\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "'''\n",
    "def llm_inf(model_name, dataset_name, category, num_shot=0, cot=False, num_examples=None, multimodal=False):\n",
    "    \n",
    "    # retrieve the dataset details\n",
    "    ds, fs_all, cot_prompt = retrieve_dataset(dataset_name, category, multimodal=multimodal)\n",
    "    print('Length of', dataset_name, 'test set:', len(ds))\n",
    "\n",
    "    # if no number of examples are provided, use the size of the test set\n",
    "    if num_examples is None:\n",
    "        num_examples = len(ds)\n",
    "        \n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # go through each example\n",
    "    for i in range(num_examples):\n",
    "        # format the prompt for the LLM\n",
    "        ques, label = format_prompt(ds[i], category, fs_all, cot_prompt, num_shot, cot, multimodal)\n",
    "\n",
    "        # setting up the inputs and inference the model\n",
    "        if multimodal:\n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"You are a content moderator that detects whether a piece of text is considered {category} (YES) or not (NO)\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": ques},\n",
    "                        {\"type\": \"image\"}\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "        else:\n",
    "            conversation = [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": f\"You are a content moderator that detects whether a piece of text is considered {category} (YES) or not (NO)\"},\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": ques},\n",
    "                    ],\n",
    "                },\n",
    "            ]\n",
    "\n",
    "        prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)  \n",
    "        if multimodal:\n",
    "            image = Image.open(f'Datasets/{dataset_name}/Images/' + ds['image_name'][i])\n",
    "            inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        else:\n",
    "            inputs = processor(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        \n",
    "        output = model.generate(**inputs, \n",
    "                                max_new_tokens=250, \n",
    "                                eos_token_id=processor.tokenizer.eos_token_id,\n",
    "                                do_sample=False,\n",
    "                                temperature=None,\n",
    "                                top_p=None,\n",
    "                                top_k=None,\n",
    "                               )\n",
    "        \n",
    "        # extract the response of the model\n",
    "        response = processor.decode(output[0], skip_special_tokens=True)\n",
    "        print('Q', i+1)\n",
    "        # print(prompt)\n",
    "        # print(\"model answer: \", response)\n",
    "        \n",
    "        llm_answer = 'NO'\n",
    "\n",
    "        # use regular expression to extract exact answer from the model\n",
    "        match1 = re.findall(r'ASSISTANT:\\s*(Yes|No)', response, re.IGNORECASE)\n",
    "        match2 = re.findall(r'Answer: (yes|no)', response, re.IGNORECASE)\n",
    "        match3 = re.findall(r'is (hate speech|offensive|toxic|cyberbullying)', response)\n",
    "\n",
    "        if match1:\n",
    "            llm_answer = match1[0].upper()\n",
    "        elif len(match2) >= 2:\n",
    "            llm_answer = match2[-1].upper()\n",
    "        elif match3:\n",
    "            llm_answer = 'YES'\n",
    "        # print('llm answer:', llm_answer)\n",
    "            \n",
    "        # check if answer from model matches the actual answer\n",
    "        if llm_answer.upper().strip() == label:\n",
    "            correct += 1\n",
    "    \n",
    "        true_labels.append(label)\n",
    "        pred_labels.append(llm_answer)\n",
    "\n",
    "    # display the metric scores when all samples have been run\n",
    "    print()\n",
    "    display_results(true_labels, pred_labels, ['YES', 'NO'], model_name, dataset_name, num_shot,cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115d3877-65fc-499f-8c00-d23d66ca88d5",
   "metadata": {},
   "source": [
    "# HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c63a7e1-39cb-43de-9e13-b5045c20f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'HateXplain'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d93b03-c86f-4bb3-a767-a02c814b13b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbd30ce-d4f0-4dba-9f36-4b0d5bf1f787",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9c5e2b-8ff0-4644-9a5e-a8cb026b0b7c",
   "metadata": {},
   "source": [
    "# Toraman hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3007dcab-b9b7-4217-b7f7-36b26c580b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toraman hate speech'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fd8a3-9da6-4782-bfda-3cdacdbf5921",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd934ce2-aaac-4eba-9635-8603b1218fff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8631ec7a-372d-4f32-bdc6-3b73bb079ab1",
   "metadata": {},
   "source": [
    "# OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff982660-a15a-413f-95f1-cc39cf1609cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OLID'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5bb0bb-3b3f-4f46-ad95-1b662e0b1690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca568494-6773-453e-84d7-ed967ce9b5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6095907f-b895-4c3c-90de-a8c3043ab43b",
   "metadata": {},
   "source": [
    "# OffensEval-TR 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfec1654-07fa-4f6c-b246-f034de2709e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OffensEval-TR 2020'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b096380-1ce9-4081-90af-715127030697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3ba4d-407a-41ec-abf3-8b6f78367a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbefa2a-974e-4be4-9c7d-039bc7ee5ce6",
   "metadata": {},
   "source": [
    "# Toxigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c94a1144-a545-4291-a15a-5113914c8873",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toxigen'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b4e54-9dfa-4b1f-a39a-6cb77cb0cbf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f11737-fe2a-4e30-81fe-3cd0108a3294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3770bf3e-3c8d-458f-86dd-05bb22e6c4c2",
   "metadata": {},
   "source": [
    "# LLM-JP Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f329d0-a987-4e3f-87bd-889cbd78f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LLM-JP Toxicity'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43d4af-19a9-4f87-a0e6-7b75106e8586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d6fca4-75c4-49fb-9aec-87b71b17a1c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4a6b3-d58f-45c7-a634-764370d83662",
   "metadata": {},
   "source": [
    "# Ejaz cyberbullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cdda6ac-a967-4577-ba62-9c7b08be0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Ejaz cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d4ef9-b3e5-42f7-a4ca-edd9df61d95b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f719561-6af6-4f50-9024-028c118c4843",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3baa698-13e8-417d-81c9-eb0f9c9f53f8",
   "metadata": {},
   "source": [
    "# SOSNet cyberbullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c971c521-5991-487b-93b8-5d46ae94cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SOSNet cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21760221-c847-437b-9fcf-df9d76032853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525b847e-42e4-4c8e-b27a-ed1a86d1bcd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9d4ffc-9dab-4e5b-9948-e2d2e488f979",
   "metadata": {},
   "source": [
    "# MMHS150K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d02d790-549c-44ff-a59c-92cfa43f0bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MMHS150K'\n",
    "category = 'hate speech'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dbc415-c8af-4c42-a862-36e503dc1e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2415850a-36c4-4039-8ffa-77cfc97b73d5",
   "metadata": {},
   "source": [
    "# MultiOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f9e0437-89b1-4a9e-bd7e-2e1aacfb0f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiOFF'\n",
    "category = 'offensive'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9f5e3-7135-46c3-9311-fb2c6c01809b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d617c3-85f4-4582-b485-4c8b5c05b628",
   "metadata": {},
   "source": [
    "# MultiToxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce648486-9a55-4d31-992d-daee0b1fe2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiToxic'\n",
    "category = 'toxic'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07066b7-d083-437b-986b-76ca7acdccdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3729582-7858-408d-9fd2-3853f8f1b313",
   "metadata": {},
   "source": [
    "# MultiBully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "503fa6cc-a742-4606-bd64-1aa28e3155d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'MultiBully'\n",
    "category = 'cyberbullying'\n",
    "multimodal = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b12229-9889-41cd-86df-f8f9be2274a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot\n",
    "num_shot = 0\n",
    "cot = False\n",
    "num_examples = None\n",
    "llm_inf(model_name, dataset_name, category, num_shot, cot, num_examples, multimodal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
