{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2d8a08-f502-431d-a82a-41562ffcd799",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bb1b3e-00e8-467a-8a30-1b7c4ac8a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re\n",
    "from utils import retrieve_dataset, display_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602bd85-55f0-4a19-9711-21ecfb1d9d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6b\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"EleutherAI/gpt-j-6b\").cuda()\n",
    "model_name = 'GPT-J'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc359615-48e9-41f1-aaf4-336b2b512977",
   "metadata": {},
   "source": [
    "# Inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae8fd94-d34f-4319-abcc-8df913f1743b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to format the prompt to be given to a LLM\n",
    "\n",
    "Inputs:\n",
    "    sample (dict): a dictionary containing a single sample from a dataset\n",
    "    category (str): the category of harmful content\n",
    "    fs_all (list): list of few shot prompts of the dataste\n",
    "    cot_prompt (str): the chain of thought prompt of the dataset\n",
    "    num_shot (int): number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "\n",
    "Returns:\n",
    "    prompt (str): the prompt to be given to a LLM\n",
    "    label (str): the label of the text\n",
    "\n",
    "'''\n",
    "def format_prompt(sample, category, fs_all, cot_prompt, num_shot=0, cot=False):\n",
    "    text = sample['text']\n",
    "    label = sample['label']\n",
    "    label_dict = {0: 'NO',\n",
    "                 1: 'YES'}\n",
    "\n",
    "    # define the prompt based on the prompting technique\n",
    "    if num_shot:\n",
    "        fs_prompt = 'Below are a set questions along with answers.\\n'\n",
    "        fs_prompt += '\\n\\n'.join(fs_all[0:num_shot])\n",
    "        prompt = f'''{fs_prompt} \n",
    "\n",
    "Now answer the following question.\n",
    "Question: Is the following text <{text}> considered as {category}?  \n",
    "Answer:'''\n",
    "\n",
    "    elif cot:\n",
    "        prompt = f'''Below is a question, along with the answer to the question and the rationale.\n",
    "{cot_prompt}\n",
    "\n",
    "Now answer the following question.\n",
    "Question: Is the following text <{text}> considered as {category}?  \n",
    "Answer:'''\n",
    "        \n",
    "    else:     \n",
    "        prompt = f'''Question: Is the following text <{text}> considered as {category}?\n",
    "Answer:'''\n",
    "    \n",
    "    return prompt, label_dict[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3259968-0289-483e-a314-f51e20c91e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function to inference and evaluate a LLM\n",
    "\n",
    "Inputs:\n",
    "    model_name (str): name of the language model\n",
    "    dataset_name (str): name of the dataset\n",
    "    category (str): the category of harmful content\n",
    "    num_shot (int): the number of shots, default is 0\n",
    "    cot (bool): whether it is chain of thought, default is False\n",
    "    num_examples (int): the number of examples to pass to the LLM, default is None\n",
    "\n",
    "Returns:\n",
    "    None\n",
    "\n",
    "'''\n",
    "def llm_inf(model_name, dataset_name, category, num_shot=0, cot=False, num_examples=None):\n",
    "    \n",
    "    # retrieve the dataset details\n",
    "    ds, fs_all, cot_prompt = retrieve_dataset(dataset_name, category, instruct=False)\n",
    "    print('Length of', dataset_name, 'test set:', len(ds))\n",
    "\n",
    "    # if no number of examples are provided, use the size of the test set\n",
    "    if num_examples is None:\n",
    "        num_examples = len(ds)\n",
    "        \n",
    "    correct = 0\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    \n",
    "    # go through each example\n",
    "    for i in range(num_examples):\n",
    "        # format the prompt for the LLM\n",
    "        prompt, label = format_prompt(ds[i], category, fs_all, cot_prompt, num_shot, cot)\n",
    "    \n",
    "        # setting up the inputs and inference the model\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").to('cuda').input_ids\n",
    "        outputs = model.generate(input_ids, \n",
    "                                max_new_tokens=150, \n",
    "                                pad_token_id=tokenizer.eos_token_id,\n",
    "                                do_sample=False,\n",
    "                                temperature=None,\n",
    "                                top_p=None,\n",
    "                                top_k=None)\n",
    "        \n",
    "        # extract the response of the model\n",
    "        response = tokenizer.batch_decode(outputs[:, input_ids.shape[1]:-1])[0].strip()\n",
    "        print('Q', i+1)\n",
    "        # print(prompt)\n",
    "        # print(\"model answer: \", response)\n",
    "\n",
    "        llm_answer = 'NO'\n",
    "\n",
    "        # use regular expression to extract exact answer from the model\n",
    "        match1 = re.findall(r'^(yes|no)', response, re.IGNORECASE)\n",
    "        match2 = re.findall(r'is considered', response)\n",
    "        match3 = re.findall(r'is not considered', response)\n",
    "\n",
    "        if match1:\n",
    "            llm_answer = match1[0].upper()\n",
    "        elif match2:\n",
    "            llm_answer = 'YES'\n",
    "        elif match3:\n",
    "            llm_answer = 'NO'\n",
    "            \n",
    "        # print('llm answer:', llm_answer)\n",
    "            \n",
    "        # check if answer from model matches the actual answer\n",
    "        if llm_answer.upper().strip() == label:\n",
    "            correct += 1\n",
    "    \n",
    "        true_labels.append(label)\n",
    "        pred_labels.append(llm_answer)\n",
    "\n",
    "    # display the metric scores when all samples have been run\n",
    "    print()\n",
    "    display_results(true_labels, pred_labels, ['YES', 'NO'], model_name, dataset_name, num_shot, cot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911d4cf0-13cf-4fc9-a219-0ede27988d7c",
   "metadata": {},
   "source": [
    "# HateXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599808f8-fa17-4e62-ab91-ab62fdec2d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'HateXplain'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3514038-0f1d-4f3d-8e51-54f054470475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b72efe-e539-4f8e-ba74-b4cedf080b69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f59c2-1787-487f-97df-b2d61df1af02",
   "metadata": {},
   "source": [
    "# Toraman hate speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7520ea15-1f0a-4e26-8a50-1ea7fb224224",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toraman hate speech'\n",
    "category = 'hate speech'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13eb9c0-4628-4c21-917c-3f7db491abcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7703c-282a-4774-a02c-f6fe2e3122e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632341ea-e80c-479b-81df-bc907c6b6609",
   "metadata": {},
   "source": [
    "# OLID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a5a9ac-bb16-43df-b5ab-9a404b2c1e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OLID'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400d1d4-c2a9-4608-8425-76d2f38e1e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750c4b7-c30b-43b1-a507-f8484c596c04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d97988-62f7-4555-9c92-418a0410004e",
   "metadata": {},
   "source": [
    "# Offenseval2020_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d48a22-da4c-4cb2-90fc-4f0d56eca7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'OffensEval-TR 2020'\n",
    "category = 'offensive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff32bf-0ff5-4eb1-b35a-2cd68b66ec47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c3c50-b360-4325-8398-fa5ac97176cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4b7307-5239-45b0-a28c-6c1814312758",
   "metadata": {},
   "source": [
    "# Toxigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda93e6-1889-474f-bc4e-b914b46716b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Toxigen'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990089f-b956-448a-b80f-2cb84d2e6f53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fa834-2f46-4ac1-b9d5-7ebf54aa1993",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678b8299-e558-467c-a1cf-53e5fcf3ff47",
   "metadata": {},
   "source": [
    "# LLM-JP Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4977489-70ff-4ca6-9f7a-8cc3c45cb478",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'LLM-JP Toxicity'\n",
    "category = 'toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c1f10-3713-4277-9689-79bcb05f948e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1bd975-87d2-4692-99a6-ace347bc1925",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b0fdd1-509b-46b9-9e13-dec3a71e57e8",
   "metadata": {},
   "source": [
    "# Ejaz cyberbullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a461159-39cb-4f74-a643-b667dacd3f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Ejaz cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f17684-3630-4b4e-b52c-5871ebdc59e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234ab4a-8ef2-44e3-896a-cc721c025e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4292c5-9ab7-440e-8bad-88196ced9aa2",
   "metadata": {},
   "source": [
    "# SOSNet cyberbullying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bee6f5-c681-482b-ab33-baa176ad8298",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'SOSNet cyberbullying'\n",
    "category = 'cyberbullying'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f84181-c708-465d-ae0a-8ad5603fea21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Zero-shot, one-shot and two-shot\n",
    "for i in range(3):\n",
    "    num_shot = i\n",
    "    llm_inf(model_name, dataset_name, category, num_shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578fbf2d-5b4d-410b-a95f-509f8a2007cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Chain of thought\n",
    "llm_inf(model_name, dataset_name, category, cot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
